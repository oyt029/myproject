package mahout02;
/*
 * Implementing Mahout using Apache Hadoop in a distributed mode
 */
		
import java.io.BufferedInputStream;
import java.io.BufferedReader;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.net.URI;
import java.net.URISyntaxException;
import java.util.Random;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;



import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.mapred.JobConf;
import org.apache.mahout.cf.taste.hadoop.item.RecommenderJob;

public class hadoop {
	private static final String HDFS_PATH = "hdfs://192.168.1.159:8020";
	
	public static void main(String args[]) throws Exception{
		
/*	"--input /opt/hadoop/tmp/Mahout/rating1.csv --usersFile /opt/hadoop/tmp/Mahout/user1.txt " +
			"--similarityClassname SIMILARITY_COOCCURRENCE --tempDir /mahoutTemp --output /opt/hadoop/tmp/Mahout/output2.txt";*/

	Random r = new Random();
		
	String inputPath = "/user/hdfs/item.csv";
	String outputPath = "/user/hdfs/result01/part-r-00000";
	String tempPath = "/tmp/"+r.nextInt(Integer.MAX_VALUE);
	String userFile = "/opt/hadoop/tmp/Mahout/user2.txt";
	String Similarity = "SIMILARITY_COSINE";
	int numRecommendations = 1000;
	
	String home = "hdfs://192.168.1.159:8020";
	String i = "--input" + " " + home+inputPath+ " "; 
	String o = "--output" + " " + home+outputPath+ " ";
	String t = "--tempDir" + " " + home+tempPath+ " ";
	String u = "--usersFile" + " " + home+userFile+ " ";
	String s = "--similarityClassname" + " " + Similarity+ " ";
	String n = "--numRecommendations" + " " + numRecommendations + " "; 
	
	String arguement = i + o + u + t + s + n;
	String [] argus = arguement.split(" ");
	
	
		for(String arg:argus)
			System.out.println(arg);
		
		
		//Configuration conf = new Configuration();
		//conf.set("fs.default.name", "hdfs://192.168.1.159:8020");
		//URI uri = new URI(conf.get("fs.default.name","."));
		try{
			
		//FileSystem fs = FileSystem.get(conf);
		
//		deleteTemp(fs,tempPath);
		
//		refreshTemp(fs, new Path(tempPath));
			
		JobConf conf = getConfig();
		hdfsdemo02 hdfs = new hdfsdemo02(conf);
		FileSystem fs = FileSystem.get(URI.create(HDFS_PATH), conf);
		RecommenderJob.main(argus);
		
		readRecom(fs,outputPath);
		}
		catch(Exception e){
			System.err.println(e.getLocalizedMessage());
		}
	}
	

	
	public static void readRecom(FileSystem fs1,String outputPath) throws URISyntaxException, IOException{

		String output = outputPath + "/part-r-00000";
		System.out.println(output);
				

        if(!fs1.exists(new Path(output)))
        	System.out.println("No file exists");
        
        BufferedReader br = new BufferedReader(new InputStreamReader(fs1.open(new Path(output))));
        String line = br.readLine();
        StringBuilder temp = new StringBuilder();
        while(line!=null){
        	temp.append(line + "\n");
        	line=br.readLine();
        }
        br.close();
		System.out.println(temp.toString());
	
		/*Path out = new Path(outputPath);
         if (fs1.exists(out)){
             fs1.delete(out, true);
             System.out.println("File deleted");
         }*/
	}
	
	public static void refreshTemp(FileSystem fs, Path tempPath) throws IOException{
		
		 if (fs.exists(tempPath)){
             fs.delete(tempPath, true);
             System.out.println("File deleted");
         }
		 
		 fs.create(tempPath);
		
	}
	private static void uploadToHdfs(String localSrc,String dst) throws FileNotFoundException,
	IOException {

// String localSrc = "C:\\Users\\Administrator\\Desktop\\SpringMvc.pdf";
// String dst = "hdfs://10.83.3.132:8020/SpringMvc.pdf";
//C:\Users\yangtao.ou\Desktop


		InputStream in = new BufferedInputStream(new FileInputStream(localSrc));
		Configuration conf = new Configuration();

		FileSystem fs = FileSystem.get(URI.create(dst), conf);
		FSDataOutputStream out = fs.create(new Path(dst));
		IOUtils.copyBytes(in, out, 4096, true);

		System.out.println("-------------------uploadToHdfs end------------------------");
}
	public static JobConf getConfig() {
		JobConf conf = new JobConf(hdfsdemo02.class);
		conf.setJobName("HdfsDAO");
		conf.addResource("/hadoop/core-site.xml");
		conf.addResource("/hadoop/hdfs-site.xml");
		conf.addResource("/hadoop/mapred-site.xml");
		return conf;
	}
}